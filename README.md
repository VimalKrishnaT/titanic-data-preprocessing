# titanic-data-preprocessing
# Titanic Dataset - Data Cleaning & Preprocessing

This project is part of the AI & ML Internship and focuses on preprocessing raw data using the Titanic dataset.

## 📌 Task Objective

To perform essential data cleaning and preprocessing steps, including:

- Handling missing values
- Encoding categorical variables
- Normalizing/standardizing numerical features
- Visualizing and removing outliers

## 🛠 Tools & Libraries Used

- Python
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Scikit-learn

## 📁 Files

- `Titanic_Preprocessing.ipynb` – Main notebook with complete preprocessing steps
- `titanic.csv` – Raw Titanic dataset
- `titanic_cleaned.csv` – Output after preprocessing (optional)

## 🧠 Key Learnings

- Understanding null value handling using imputation
- Difference between label encoding and one-hot encoding
- Feature scaling techniques: standardization vs normalization
- Identifying and removing outliers using IQR method and boxplots

## 📊 Dataset Source

[Titanic Dataset on Kaggle](https://www.kaggle.com/datasets/yasserh/titanic-dataset)

## ✅ Output

A cleaned and preprocessed dataset ready for machine learning model building.

---

